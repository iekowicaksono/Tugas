{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsGqx_ai_N8F"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow 2.0\n",
        "#tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "\n",
        "#! pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "# assert len(tf.config.list_physical_devices('GPU')) > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2dQsHI3_N8K"
      },
      "outputs": [],
      "source": [
        "#mnist = tf.keras.datasets.mnist\n",
        "#Training Fashion MNIST Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
        "train_labels = (train_labels).astype(np.int64)\n",
        "test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)\n",
        "test_labels = (test_labels).astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDBsR2lP_N8O",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "random_inds = np.random.choice(60000,36)\n",
        "for i in range(36):\n",
        "    plt.subplot(6,6,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image_ind = random_inds[i]\n",
        "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[image_ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vec9qcJs-9W5"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "\n",
        "        # TODO: Define the first convolutional layer\n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Conv2D(filters=24, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Conv2D(filters=24, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Conv2D(filters=24, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        # tf.keras.layers.Conv2D('''TODO''') \n",
        "\n",
        "        # TODO: Define the first max pooling layer\n",
        "        #tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        # tf.keras.layers.MaxPool2D('''TODO''')\n",
        "\n",
        "        # TODO: Define the second convolutional layer\n",
        "        #tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        # tf.keras.layers.Conv2D('''TODO''')\n",
        "\n",
        "        # TODO: Define the second max pooling layer\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        # tf.keras.layers.MaxPool2D('''TODO''')\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        #tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "\n",
        "        # TODO: Define the last Dense layer to output the classification \n",
        "        # probabilities. Pay attention to the activation needed a probability\n",
        "        # output\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        # [TODO Dense layer to output classification probabilities]\n",
        "    ])\n",
        "    \n",
        "    return cnn_model\n",
        "  \n",
        "cnn_model = build_cnn_model()\n",
        "# Initialize the model by passing some data through\n",
        "cnn_model.predict(train_images[[0]])\n",
        "# Print the summary of the layers in the model.\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vheyanDkCg6a"
      },
      "outputs": [],
      "source": [
        "'''TODO: Define the batch size and the number of epochs to use during training'''\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "learning_rate = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''TODO: Define the compile operation with your optimizer and learning rate of choice'''\n",
        "cnn_model.compile(\n",
        "              optimizer=tf.keras.optimizers.Adamax(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# cnn_model.compile(optimizer='''TODO''', loss='''TODO''', metrics=['accuracy']) # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdrGZVmWDK4p"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "'''TODO: Use model.fit to train the CNN model, with the same batch_size and number of epochs previously used.'''\n",
        "#callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "history = cnn_model.fit(train_images, train_labels, validation_split = 0.1, batch_size=BATCH_SIZE, epochs=EPOCHS,)# callbacks=[callback], verbose=0)\n",
        "# cnn_model.fit('''TODO''')\n",
        "end_time = datetime.now()\n",
        "#round(cnn_model.optimizer.learning_rate.numpy(), 5)\n",
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('akurasi model tanpa scheduler')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDm4znZcDtNl"
      },
      "outputs": [],
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "# test_loss, test_acc = # TODO\n",
        "\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "outputs": [],
      "source": [
        "'''TODO: Define learning rate scheduller'''\n",
        "initial_learning_rate = 1e-3\n",
        "epochs = 10\n",
        "powers = 1\n",
        "decay = learning_rate/EPOCHS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''TODO: Defined polinomial decay'''\n",
        "class lr_polynomial_decay:\n",
        "\tdef __init__(self, epochs=epochs, learning_rate=initial_learning_rate, power=powers):\n",
        "\t\t# store the maximum number of epochs, base learning rate,\n",
        "\t\t# and power of the polynomial\n",
        "\t\tself.epochs = epochs\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.power = power\n",
        "        \n",
        "\tdef __call__(self, epoch):\n",
        "\t\t# compute the new learning rate based on polynomial decay\n",
        "\t\tdecay = (1 - (epoch / float(self.epochs))) ** self.power\n",
        "\t\tupdated_eta = self.initial_learning_rate * decay\n",
        "\t\t# return the new learning rate\n",
        "\t\treturn float(updated_eta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lr_time_based_decay(epochs, learning_rate):\n",
        "        return (learning_rate * 1) / (1 + (decay * epochs))\n",
        "\n",
        "def lr_exp_decay(epoch):\n",
        "    k = 0.1\n",
        "    return initial_learning_rate * math.exp(-k*epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#curScheduler = lr_polynomial_decay(epochs=EPOCHS, learning_rate=initial_learning_rate, power=POWER)\n",
        "#curScheduler = lr_time_based_decay(epochs=epochs, learning_rate=initial_learning_rate)\n",
        "\n",
        "'''TODO: Define the compile operation with your optimizer and learning rate of choice'''\n",
        "cnn_model.compile(\n",
        "              optimizer='adamax',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#round(cnn_model.optimizer.lr.numpy(), 10)\n",
        "# cnn_model.compile(optimizer='''TODO''', loss='''TODO''', metrics=['accuracy']) # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "'''TODO: Use model.fit to train the CNN model, with the same batch_size and number of epochs previously used.'''\n",
        "#callback = tf.keras.callbacks.LearningRateScheduler(curScheduler)\n",
        "history_scheduler = cnn_model.fit(train_images, train_labels, validation_split = 0.1, batch_size=BATCH_SIZE, \n",
        "                                    epochs=EPOCHS)#, callbacks=[callback], verbose=1)\n",
        "# cnn_model.fit('''TODO''')\n",
        "end_time = datetime.now()\n",
        "#round(cnn_model.optimizer.learning_rate.numpy(), 5)\n",
        "history_scheduler.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
        "plt.plot(history_scheduler.history['accuracy'])\n",
        "plt.plot(history_scheduler.history['val_accuracy'])\n",
        "plt.title('akurasi model dengan scheduler')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "# test_loss, test_acc = # TODO\n",
        "\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Xmf_JRJa_N8C"
      ],
      "name": "Part1_MNIST_Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
