{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "#dataset_path = r\"C:\\Users\\Dell\\Documents\\PhD\\Semester 3\\Pebelejaran Mesin Lanjut\\Tugas\\boston.csv\"\n",
        "#boston = pd.read_csv(dataset_path)\n",
        "\n",
        "#boston.head()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "x_train_df = pd.DataFrame(x_train, columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
        "x_test_df = pd.DataFrame(x_test, columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
        "y_train_df = pd.DataFrame(y_train, columns=['MEDV'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['MEDV'])\n",
        "#y_train_df.head()\n",
        "#y_train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_df['MEDV'] = y_train_df\n",
        "x_test_df['MEDV'] = y_test_df\n",
        "#x_train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    404.000000\n",
              "mean      22.395050\n",
              "std        9.210442\n",
              "min        5.000000\n",
              "25%       16.675000\n",
              "50%       20.750000\n",
              "75%       24.800000\n",
              "max       50.000000\n",
              "Name: MEDV, dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_df['MEDV'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                960       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               33280     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               33280     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,185\n",
            "Trainable params: 109,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#x = boston[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']]\n",
        "#y = boston['MEDV']\n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(14,)))#,\n",
        "                               #kernel_regularizer=tf.keras.regularizers.L2()))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu')),\n",
        "model.add(tf.keras.layers.Dense(512, activation='tanh')),\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu')),\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu')),\n",
        "model.add(tf.keras.layers.Dense(512, activation='sigmoid')),\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='mean_squared_logarithmic_error',\n",
        "             optimizer='Adam',\n",
        "             metrics=['mean_squared_logarithmic_error'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 2s 51ms/step - loss: 5.3880 - mean_squared_logarithmic_error: 5.3880 - val_loss: 1.9759 - val_mean_squared_logarithmic_error: 1.9759\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2481 - mean_squared_logarithmic_error: 1.2481 - val_loss: 0.6698 - val_mean_squared_logarithmic_error: 0.6698\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4628 - mean_squared_logarithmic_error: 0.4628 - val_loss: 0.3469 - val_mean_squared_logarithmic_error: 0.3469\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2687 - mean_squared_logarithmic_error: 0.2687 - val_loss: 0.2467 - val_mean_squared_logarithmic_error: 0.2467\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2128 - mean_squared_logarithmic_error: 0.2128 - val_loss: 0.2093 - val_mean_squared_logarithmic_error: 0.2093\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1907 - mean_squared_logarithmic_error: 0.1907 - val_loss: 0.1929 - val_mean_squared_logarithmic_error: 0.1929\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1812 - mean_squared_logarithmic_error: 0.1812 - val_loss: 0.1845 - val_mean_squared_logarithmic_error: 0.1845\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1760 - mean_squared_logarithmic_error: 0.1760 - val_loss: 0.1794 - val_mean_squared_logarithmic_error: 0.1794\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1730 - mean_squared_logarithmic_error: 0.1730 - val_loss: 0.1757 - val_mean_squared_logarithmic_error: 0.1757\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1709 - mean_squared_logarithmic_error: 0.1709 - val_loss: 0.1727 - val_mean_squared_logarithmic_error: 0.1727\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1691 - mean_squared_logarithmic_error: 0.1691 - val_loss: 0.1703 - val_mean_squared_logarithmic_error: 0.1703\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1675 - mean_squared_logarithmic_error: 0.1675 - val_loss: 0.1679 - val_mean_squared_logarithmic_error: 0.1679\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1660 - mean_squared_logarithmic_error: 0.1660 - val_loss: 0.1657 - val_mean_squared_logarithmic_error: 0.1657\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1647 - mean_squared_logarithmic_error: 0.1647 - val_loss: 0.1639 - val_mean_squared_logarithmic_error: 0.1639\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1637 - mean_squared_logarithmic_error: 0.1637 - val_loss: 0.1623 - val_mean_squared_logarithmic_error: 0.1623\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1628 - mean_squared_logarithmic_error: 0.1628 - val_loss: 0.1610 - val_mean_squared_logarithmic_error: 0.1610\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1620 - mean_squared_logarithmic_error: 0.1620 - val_loss: 0.1597 - val_mean_squared_logarithmic_error: 0.1597\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1613 - mean_squared_logarithmic_error: 0.1613 - val_loss: 0.1583 - val_mean_squared_logarithmic_error: 0.1583\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1603 - mean_squared_logarithmic_error: 0.1603 - val_loss: 0.1568 - val_mean_squared_logarithmic_error: 0.1568\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1595 - mean_squared_logarithmic_error: 0.1595 - val_loss: 0.1556 - val_mean_squared_logarithmic_error: 0.1556\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1587 - mean_squared_logarithmic_error: 0.1587 - val_loss: 0.1542 - val_mean_squared_logarithmic_error: 0.1542\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1580 - mean_squared_logarithmic_error: 0.1580 - val_loss: 0.1528 - val_mean_squared_logarithmic_error: 0.1528\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1572 - mean_squared_logarithmic_error: 0.1572 - val_loss: 0.1512 - val_mean_squared_logarithmic_error: 0.1512\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1563 - mean_squared_logarithmic_error: 0.1563 - val_loss: 0.1497 - val_mean_squared_logarithmic_error: 0.1497\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1555 - mean_squared_logarithmic_error: 0.1555 - val_loss: 0.1484 - val_mean_squared_logarithmic_error: 0.1484\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1550 - mean_squared_logarithmic_error: 0.1550 - val_loss: 0.1475 - val_mean_squared_logarithmic_error: 0.1475\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1545 - mean_squared_logarithmic_error: 0.1545 - val_loss: 0.1467 - val_mean_squared_logarithmic_error: 0.1467\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1541 - mean_squared_logarithmic_error: 0.1541 - val_loss: 0.1459 - val_mean_squared_logarithmic_error: 0.1459\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1537 - mean_squared_logarithmic_error: 0.1537 - val_loss: 0.1452 - val_mean_squared_logarithmic_error: 0.1452\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1533 - mean_squared_logarithmic_error: 0.1533 - val_loss: 0.1446 - val_mean_squared_logarithmic_error: 0.1446\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1529 - mean_squared_logarithmic_error: 0.1529 - val_loss: 0.1439 - val_mean_squared_logarithmic_error: 0.1439\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1526 - mean_squared_logarithmic_error: 0.1526 - val_loss: 0.1434 - val_mean_squared_logarithmic_error: 0.1434\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1522 - mean_squared_logarithmic_error: 0.1522 - val_loss: 0.1428 - val_mean_squared_logarithmic_error: 0.1428\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1519 - mean_squared_logarithmic_error: 0.1519 - val_loss: 0.1421 - val_mean_squared_logarithmic_error: 0.1421\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1515 - mean_squared_logarithmic_error: 0.1515 - val_loss: 0.1414 - val_mean_squared_logarithmic_error: 0.1414\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1511 - mean_squared_logarithmic_error: 0.1511 - val_loss: 0.1408 - val_mean_squared_logarithmic_error: 0.1408\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1508 - mean_squared_logarithmic_error: 0.1508 - val_loss: 0.1399 - val_mean_squared_logarithmic_error: 0.1399\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1503 - mean_squared_logarithmic_error: 0.1503 - val_loss: 0.1392 - val_mean_squared_logarithmic_error: 0.1392\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1499 - mean_squared_logarithmic_error: 0.1499 - val_loss: 0.1387 - val_mean_squared_logarithmic_error: 0.1387\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1496 - mean_squared_logarithmic_error: 0.1496 - val_loss: 0.1383 - val_mean_squared_logarithmic_error: 0.1383\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1492 - mean_squared_logarithmic_error: 0.1492 - val_loss: 0.1380 - val_mean_squared_logarithmic_error: 0.1380\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1488 - mean_squared_logarithmic_error: 0.1488 - val_loss: 0.1374 - val_mean_squared_logarithmic_error: 0.1374\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1482 - mean_squared_logarithmic_error: 0.1482 - val_loss: 0.1365 - val_mean_squared_logarithmic_error: 0.1365\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1474 - mean_squared_logarithmic_error: 0.1474 - val_loss: 0.1358 - val_mean_squared_logarithmic_error: 0.1358\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1466 - mean_squared_logarithmic_error: 0.1466 - val_loss: 0.1350 - val_mean_squared_logarithmic_error: 0.1350\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1454 - mean_squared_logarithmic_error: 0.1454 - val_loss: 0.1347 - val_mean_squared_logarithmic_error: 0.1347\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1443 - mean_squared_logarithmic_error: 0.1443 - val_loss: 0.1339 - val_mean_squared_logarithmic_error: 0.1339\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1427 - mean_squared_logarithmic_error: 0.1427 - val_loss: 0.1324 - val_mean_squared_logarithmic_error: 0.1324\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1416 - mean_squared_logarithmic_error: 0.1416 - val_loss: 0.1306 - val_mean_squared_logarithmic_error: 0.1306\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1400 - mean_squared_logarithmic_error: 0.1400 - val_loss: 0.1296 - val_mean_squared_logarithmic_error: 0.1296\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1366 - mean_squared_logarithmic_error: 0.1366 - val_loss: 0.1291 - val_mean_squared_logarithmic_error: 0.1291\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1336 - mean_squared_logarithmic_error: 0.1336 - val_loss: 0.1291 - val_mean_squared_logarithmic_error: 0.1291\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1305 - mean_squared_logarithmic_error: 0.1305 - val_loss: 0.1280 - val_mean_squared_logarithmic_error: 0.1280\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1251 - mean_squared_logarithmic_error: 0.1251 - val_loss: 0.1229 - val_mean_squared_logarithmic_error: 0.1229\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1212 - mean_squared_logarithmic_error: 0.1212 - val_loss: 0.1199 - val_mean_squared_logarithmic_error: 0.1199\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1184 - mean_squared_logarithmic_error: 0.1184 - val_loss: 0.1208 - val_mean_squared_logarithmic_error: 0.1208\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1168 - mean_squared_logarithmic_error: 0.1168 - val_loss: 0.1167 - val_mean_squared_logarithmic_error: 0.1167\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1177 - mean_squared_logarithmic_error: 0.1177 - val_loss: 0.1128 - val_mean_squared_logarithmic_error: 0.1128\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1144 - mean_squared_logarithmic_error: 0.1144 - val_loss: 0.1144 - val_mean_squared_logarithmic_error: 0.1144\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1145 - mean_squared_logarithmic_error: 0.1145 - val_loss: 0.1122 - val_mean_squared_logarithmic_error: 0.1122\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1170 - mean_squared_logarithmic_error: 0.1170 - val_loss: 0.1125 - val_mean_squared_logarithmic_error: 0.1125\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1113 - mean_squared_logarithmic_error: 0.1113 - val_loss: 0.1198 - val_mean_squared_logarithmic_error: 0.1198\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1119 - mean_squared_logarithmic_error: 0.1119 - val_loss: 0.1106 - val_mean_squared_logarithmic_error: 0.1106\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1103 - mean_squared_logarithmic_error: 0.1103 - val_loss: 0.1080 - val_mean_squared_logarithmic_error: 0.1080\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1090 - mean_squared_logarithmic_error: 0.1090 - val_loss: 0.1104 - val_mean_squared_logarithmic_error: 0.1104\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_logarithmic_error: 0.1086 - val_loss: 0.1104 - val_mean_squared_logarithmic_error: 0.1104\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1068 - mean_squared_logarithmic_error: 0.1068 - val_loss: 0.1030 - val_mean_squared_logarithmic_error: 0.1030\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1060 - mean_squared_logarithmic_error: 0.1060 - val_loss: 0.1102 - val_mean_squared_logarithmic_error: 0.1102\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1111 - mean_squared_logarithmic_error: 0.1111 - val_loss: 0.1101 - val_mean_squared_logarithmic_error: 0.1101\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1065 - mean_squared_logarithmic_error: 0.1065 - val_loss: 0.1022 - val_mean_squared_logarithmic_error: 0.1022\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1044 - mean_squared_logarithmic_error: 0.1044 - val_loss: 0.1207 - val_mean_squared_logarithmic_error: 0.1207\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1074 - mean_squared_logarithmic_error: 0.1074 - val_loss: 0.1110 - val_mean_squared_logarithmic_error: 0.1110\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1042 - mean_squared_logarithmic_error: 0.1042 - val_loss: 0.1059 - val_mean_squared_logarithmic_error: 0.1059\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1026 - mean_squared_logarithmic_error: 0.1026 - val_loss: 0.0991 - val_mean_squared_logarithmic_error: 0.0991\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1033 - mean_squared_logarithmic_error: 0.1033 - val_loss: 0.1004 - val_mean_squared_logarithmic_error: 0.1004\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1007 - mean_squared_logarithmic_error: 0.1007 - val_loss: 0.1031 - val_mean_squared_logarithmic_error: 0.1031\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0998 - mean_squared_logarithmic_error: 0.0998 - val_loss: 0.1077 - val_mean_squared_logarithmic_error: 0.1077\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0996 - mean_squared_logarithmic_error: 0.0996 - val_loss: 0.1011 - val_mean_squared_logarithmic_error: 0.1011\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0973 - mean_squared_logarithmic_error: 0.0973 - val_loss: 0.0977 - val_mean_squared_logarithmic_error: 0.0977\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0957 - mean_squared_logarithmic_error: 0.0957 - val_loss: 0.1066 - val_mean_squared_logarithmic_error: 0.1066\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0953 - mean_squared_logarithmic_error: 0.0953 - val_loss: 0.0970 - val_mean_squared_logarithmic_error: 0.0970\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0936 - mean_squared_logarithmic_error: 0.0936 - val_loss: 0.1015 - val_mean_squared_logarithmic_error: 0.1015\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0939 - mean_squared_logarithmic_error: 0.0939 - val_loss: 0.0949 - val_mean_squared_logarithmic_error: 0.0949\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0917 - mean_squared_logarithmic_error: 0.0917 - val_loss: 0.1033 - val_mean_squared_logarithmic_error: 0.1033\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0949 - mean_squared_logarithmic_error: 0.0949 - val_loss: 0.0861 - val_mean_squared_logarithmic_error: 0.0861\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0980 - mean_squared_logarithmic_error: 0.0980 - val_loss: 0.0927 - val_mean_squared_logarithmic_error: 0.0927\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1082 - mean_squared_logarithmic_error: 0.1082 - val_loss: 0.0952 - val_mean_squared_logarithmic_error: 0.0952\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0913 - mean_squared_logarithmic_error: 0.0913 - val_loss: 0.0853 - val_mean_squared_logarithmic_error: 0.0853\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0891 - mean_squared_logarithmic_error: 0.0891 - val_loss: 0.0914 - val_mean_squared_logarithmic_error: 0.0914\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0888 - mean_squared_logarithmic_error: 0.0888 - val_loss: 0.0925 - val_mean_squared_logarithmic_error: 0.0925\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0847 - mean_squared_logarithmic_error: 0.0847 - val_loss: 0.0843 - val_mean_squared_logarithmic_error: 0.0843\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0830 - mean_squared_logarithmic_error: 0.0830 - val_loss: 0.0841 - val_mean_squared_logarithmic_error: 0.0841\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0791 - mean_squared_logarithmic_error: 0.0791 - val_loss: 0.0834 - val_mean_squared_logarithmic_error: 0.0834\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0817 - mean_squared_logarithmic_error: 0.0817 - val_loss: 0.0784 - val_mean_squared_logarithmic_error: 0.0784\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0794 - mean_squared_logarithmic_error: 0.0794 - val_loss: 0.0771 - val_mean_squared_logarithmic_error: 0.0771\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0787 - mean_squared_logarithmic_error: 0.0787 - val_loss: 0.0767 - val_mean_squared_logarithmic_error: 0.0767\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0761 - mean_squared_logarithmic_error: 0.0761 - val_loss: 0.0773 - val_mean_squared_logarithmic_error: 0.0773\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0731 - mean_squared_logarithmic_error: 0.0731 - val_loss: 0.0741 - val_mean_squared_logarithmic_error: 0.0741\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0700 - mean_squared_logarithmic_error: 0.0700 - val_loss: 0.0722 - val_mean_squared_logarithmic_error: 0.0722\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0679 - mean_squared_logarithmic_error: 0.0679 - val_loss: 0.0710 - val_mean_squared_logarithmic_error: 0.0710\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0665 - mean_squared_logarithmic_error: 0.0665 - val_loss: 0.0690 - val_mean_squared_logarithmic_error: 0.0690\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0661 - mean_squared_logarithmic_error: 0.0661 - val_loss: 0.0703 - val_mean_squared_logarithmic_error: 0.0703\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0672 - mean_squared_logarithmic_error: 0.0672 - val_loss: 0.0727 - val_mean_squared_logarithmic_error: 0.0727\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0714 - mean_squared_logarithmic_error: 0.0714 - val_loss: 0.0679 - val_mean_squared_logarithmic_error: 0.0679\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0688 - mean_squared_logarithmic_error: 0.0688 - val_loss: 0.0720 - val_mean_squared_logarithmic_error: 0.0720\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0698 - mean_squared_logarithmic_error: 0.0698 - val_loss: 0.0684 - val_mean_squared_logarithmic_error: 0.0684\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0646 - mean_squared_logarithmic_error: 0.0646 - val_loss: 0.0723 - val_mean_squared_logarithmic_error: 0.0723\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0736 - mean_squared_logarithmic_error: 0.0736 - val_loss: 0.0654 - val_mean_squared_logarithmic_error: 0.0654\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0702 - mean_squared_logarithmic_error: 0.0702 - val_loss: 0.0691 - val_mean_squared_logarithmic_error: 0.0691\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0667 - mean_squared_logarithmic_error: 0.0667 - val_loss: 0.0682 - val_mean_squared_logarithmic_error: 0.0682\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0624 - mean_squared_logarithmic_error: 0.0624 - val_loss: 0.0721 - val_mean_squared_logarithmic_error: 0.0721\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0630 - mean_squared_logarithmic_error: 0.0630 - val_loss: 0.0634 - val_mean_squared_logarithmic_error: 0.0634\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0609 - mean_squared_logarithmic_error: 0.0609 - val_loss: 0.0695 - val_mean_squared_logarithmic_error: 0.0695\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0665 - mean_squared_logarithmic_error: 0.0665 - val_loss: 0.0678 - val_mean_squared_logarithmic_error: 0.0678\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0614 - mean_squared_logarithmic_error: 0.0614 - val_loss: 0.0601 - val_mean_squared_logarithmic_error: 0.0601\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0570 - mean_squared_logarithmic_error: 0.0570 - val_loss: 0.0641 - val_mean_squared_logarithmic_error: 0.0641\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0591 - mean_squared_logarithmic_error: 0.0591 - val_loss: 0.0612 - val_mean_squared_logarithmic_error: 0.0612\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0590 - mean_squared_logarithmic_error: 0.0590 - val_loss: 0.0586 - val_mean_squared_logarithmic_error: 0.0586\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0542 - mean_squared_logarithmic_error: 0.0542 - val_loss: 0.0588 - val_mean_squared_logarithmic_error: 0.0588\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0535 - mean_squared_logarithmic_error: 0.0535 - val_loss: 0.0589 - val_mean_squared_logarithmic_error: 0.0589\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0544 - mean_squared_logarithmic_error: 0.0544 - val_loss: 0.0612 - val_mean_squared_logarithmic_error: 0.0612\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0561 - mean_squared_logarithmic_error: 0.0561 - val_loss: 0.0574 - val_mean_squared_logarithmic_error: 0.0574\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0517 - mean_squared_logarithmic_error: 0.0517 - val_loss: 0.0565 - val_mean_squared_logarithmic_error: 0.0565\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0511 - mean_squared_logarithmic_error: 0.0511 - val_loss: 0.0541 - val_mean_squared_logarithmic_error: 0.0541\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0505 - mean_squared_logarithmic_error: 0.0505 - val_loss: 0.0560 - val_mean_squared_logarithmic_error: 0.0560\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0546 - mean_squared_logarithmic_error: 0.0546 - val_loss: 0.0550 - val_mean_squared_logarithmic_error: 0.0550\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0551 - mean_squared_logarithmic_error: 0.0551 - val_loss: 0.0550 - val_mean_squared_logarithmic_error: 0.0550\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0517 - mean_squared_logarithmic_error: 0.0517 - val_loss: 0.0526 - val_mean_squared_logarithmic_error: 0.0526\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0489 - mean_squared_logarithmic_error: 0.0489 - val_loss: 0.0515 - val_mean_squared_logarithmic_error: 0.0515\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0487 - mean_squared_logarithmic_error: 0.0487 - val_loss: 0.0502 - val_mean_squared_logarithmic_error: 0.0502\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0470 - mean_squared_logarithmic_error: 0.0470 - val_loss: 0.0489 - val_mean_squared_logarithmic_error: 0.0489\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0448 - mean_squared_logarithmic_error: 0.0448 - val_loss: 0.0558 - val_mean_squared_logarithmic_error: 0.0558\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0487 - mean_squared_logarithmic_error: 0.0487 - val_loss: 0.0494 - val_mean_squared_logarithmic_error: 0.0494\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0450 - mean_squared_logarithmic_error: 0.0450 - val_loss: 0.0466 - val_mean_squared_logarithmic_error: 0.0466\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0422 - mean_squared_logarithmic_error: 0.0422 - val_loss: 0.0486 - val_mean_squared_logarithmic_error: 0.0486\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0433 - mean_squared_logarithmic_error: 0.0433 - val_loss: 0.0470 - val_mean_squared_logarithmic_error: 0.0470\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0426 - mean_squared_logarithmic_error: 0.0426 - val_loss: 0.0472 - val_mean_squared_logarithmic_error: 0.0472\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0415 - mean_squared_logarithmic_error: 0.0415 - val_loss: 0.0442 - val_mean_squared_logarithmic_error: 0.0442\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0393 - mean_squared_logarithmic_error: 0.0393 - val_loss: 0.0499 - val_mean_squared_logarithmic_error: 0.0499\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0412 - mean_squared_logarithmic_error: 0.0412 - val_loss: 0.0471 - val_mean_squared_logarithmic_error: 0.0471\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0417 - mean_squared_logarithmic_error: 0.0417 - val_loss: 0.0424 - val_mean_squared_logarithmic_error: 0.0424\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0364 - mean_squared_logarithmic_error: 0.0364 - val_loss: 0.0409 - val_mean_squared_logarithmic_error: 0.0409\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0372 - mean_squared_logarithmic_error: 0.0372 - val_loss: 0.0407 - val_mean_squared_logarithmic_error: 0.0407\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0354 - mean_squared_logarithmic_error: 0.0354 - val_loss: 0.0398 - val_mean_squared_logarithmic_error: 0.0398\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0342 - mean_squared_logarithmic_error: 0.0342 - val_loss: 0.0416 - val_mean_squared_logarithmic_error: 0.0416\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0434 - mean_squared_logarithmic_error: 0.0434 - val_loss: 0.0386 - val_mean_squared_logarithmic_error: 0.0386\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0396 - mean_squared_logarithmic_error: 0.0396 - val_loss: 0.0682 - val_mean_squared_logarithmic_error: 0.0682\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0556 - mean_squared_logarithmic_error: 0.0556 - val_loss: 0.0402 - val_mean_squared_logarithmic_error: 0.0402\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0400 - mean_squared_logarithmic_error: 0.0400 - val_loss: 0.0431 - val_mean_squared_logarithmic_error: 0.0431\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0425 - mean_squared_logarithmic_error: 0.0425 - val_loss: 0.0499 - val_mean_squared_logarithmic_error: 0.0499\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0437 - mean_squared_logarithmic_error: 0.0437 - val_loss: 0.0359 - val_mean_squared_logarithmic_error: 0.0359\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0386 - mean_squared_logarithmic_error: 0.0386 - val_loss: 0.0379 - val_mean_squared_logarithmic_error: 0.0379\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0382 - mean_squared_logarithmic_error: 0.0382 - val_loss: 0.0493 - val_mean_squared_logarithmic_error: 0.0493\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0389 - mean_squared_logarithmic_error: 0.0389 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0380 - mean_squared_logarithmic_error: 0.0380 - val_loss: 0.0500 - val_mean_squared_logarithmic_error: 0.0500\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0430 - mean_squared_logarithmic_error: 0.0430 - val_loss: 0.0390 - val_mean_squared_logarithmic_error: 0.0390\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0357 - mean_squared_logarithmic_error: 0.0357 - val_loss: 0.0333 - val_mean_squared_logarithmic_error: 0.0333\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0319 - mean_squared_logarithmic_error: 0.0319 - val_loss: 0.0368 - val_mean_squared_logarithmic_error: 0.0368\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0355 - mean_squared_logarithmic_error: 0.0355 - val_loss: 0.0346 - val_mean_squared_logarithmic_error: 0.0346\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0327 - mean_squared_logarithmic_error: 0.0327 - val_loss: 0.0334 - val_mean_squared_logarithmic_error: 0.0334\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0312 - mean_squared_logarithmic_error: 0.0312 - val_loss: 0.0393 - val_mean_squared_logarithmic_error: 0.0393\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0366 - mean_squared_logarithmic_error: 0.0366 - val_loss: 0.0367 - val_mean_squared_logarithmic_error: 0.0367\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0319 - mean_squared_logarithmic_error: 0.0319 - val_loss: 0.0327 - val_mean_squared_logarithmic_error: 0.0327\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0301 - mean_squared_logarithmic_error: 0.0301 - val_loss: 0.0305 - val_mean_squared_logarithmic_error: 0.0305\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0290 - mean_squared_logarithmic_error: 0.0290 - val_loss: 0.0304 - val_mean_squared_logarithmic_error: 0.0304\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0278 - mean_squared_logarithmic_error: 0.0278 - val_loss: 0.0326 - val_mean_squared_logarithmic_error: 0.0326\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0294 - mean_squared_logarithmic_error: 0.0294 - val_loss: 0.0331 - val_mean_squared_logarithmic_error: 0.0331\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0292 - mean_squared_logarithmic_error: 0.0292 - val_loss: 0.0491 - val_mean_squared_logarithmic_error: 0.0491\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0449 - mean_squared_logarithmic_error: 0.0449 - val_loss: 0.0354 - val_mean_squared_logarithmic_error: 0.0354\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0408 - mean_squared_logarithmic_error: 0.0408 - val_loss: 0.0338 - val_mean_squared_logarithmic_error: 0.0338\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0373 - mean_squared_logarithmic_error: 0.0373 - val_loss: 0.0386 - val_mean_squared_logarithmic_error: 0.0386\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0357 - mean_squared_logarithmic_error: 0.0357 - val_loss: 0.0305 - val_mean_squared_logarithmic_error: 0.0305\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0313 - mean_squared_logarithmic_error: 0.0313 - val_loss: 0.0302 - val_mean_squared_logarithmic_error: 0.0302\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0299 - mean_squared_logarithmic_error: 0.0299 - val_loss: 0.0286 - val_mean_squared_logarithmic_error: 0.0286\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0274 - mean_squared_logarithmic_error: 0.0274 - val_loss: 0.0293 - val_mean_squared_logarithmic_error: 0.0293\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0305 - mean_squared_logarithmic_error: 0.0305 - val_loss: 0.0335 - val_mean_squared_logarithmic_error: 0.0335\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0391 - mean_squared_logarithmic_error: 0.0391 - val_loss: 0.0515 - val_mean_squared_logarithmic_error: 0.0515\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0408 - mean_squared_logarithmic_error: 0.0408 - val_loss: 0.0417 - val_mean_squared_logarithmic_error: 0.0417\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0385 - mean_squared_logarithmic_error: 0.0385 - val_loss: 0.0415 - val_mean_squared_logarithmic_error: 0.0415\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0334 - mean_squared_logarithmic_error: 0.0334 - val_loss: 0.0311 - val_mean_squared_logarithmic_error: 0.0311\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0312 - mean_squared_logarithmic_error: 0.0312 - val_loss: 0.0289 - val_mean_squared_logarithmic_error: 0.0289\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0263 - mean_squared_logarithmic_error: 0.0263 - val_loss: 0.0279 - val_mean_squared_logarithmic_error: 0.0279\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0259 - mean_squared_logarithmic_error: 0.0259 - val_loss: 0.0252 - val_mean_squared_logarithmic_error: 0.0252\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0248 - mean_squared_logarithmic_error: 0.0248 - val_loss: 0.0306 - val_mean_squared_logarithmic_error: 0.0306\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0293 - mean_squared_logarithmic_error: 0.0293 - val_loss: 0.0323 - val_mean_squared_logarithmic_error: 0.0323\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0284 - mean_squared_logarithmic_error: 0.0284 - val_loss: 0.0317 - val_mean_squared_logarithmic_error: 0.0317\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0259 - mean_squared_logarithmic_error: 0.0259 - val_loss: 0.0281 - val_mean_squared_logarithmic_error: 0.0281\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0264 - mean_squared_logarithmic_error: 0.0264 - val_loss: 0.0284 - val_mean_squared_logarithmic_error: 0.0284\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0250 - mean_squared_logarithmic_error: 0.0250 - val_loss: 0.0278 - val_mean_squared_logarithmic_error: 0.0278\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0269 - mean_squared_logarithmic_error: 0.0269 - val_loss: 0.0255 - val_mean_squared_logarithmic_error: 0.0255\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0389 - mean_squared_logarithmic_error: 0.0389 - val_loss: 0.0312 - val_mean_squared_logarithmic_error: 0.0312\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0326 - mean_squared_logarithmic_error: 0.0326 - val_loss: 0.0286 - val_mean_squared_logarithmic_error: 0.0286\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0334 - mean_squared_logarithmic_error: 0.0334 - val_loss: 0.0271 - val_mean_squared_logarithmic_error: 0.0271\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0271 - mean_squared_logarithmic_error: 0.0271 - val_loss: 0.0267 - val_mean_squared_logarithmic_error: 0.0267\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0247 - mean_squared_logarithmic_error: 0.0247 - val_loss: 0.0251 - val_mean_squared_logarithmic_error: 0.0251\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0247 - mean_squared_logarithmic_error: 0.0247 - val_loss: 0.0236 - val_mean_squared_logarithmic_error: 0.0236\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0247 - mean_squared_logarithmic_error: 0.0247 - val_loss: 0.0239 - val_mean_squared_logarithmic_error: 0.0239\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0244 - mean_squared_logarithmic_error: 0.0244 - val_loss: 0.0227 - val_mean_squared_logarithmic_error: 0.0227\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0234 - mean_squared_logarithmic_error: 0.0234 - val_loss: 0.0223 - val_mean_squared_logarithmic_error: 0.0223\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0218 - mean_squared_logarithmic_error: 0.0218 - val_loss: 0.0238 - val_mean_squared_logarithmic_error: 0.0238\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'loss': [5.38803768157959,\n",
              "  1.248118281364441,\n",
              "  0.4627559781074524,\n",
              "  0.268706351518631,\n",
              "  0.21277044713497162,\n",
              "  0.19066660106182098,\n",
              "  0.18117688596248627,\n",
              "  0.17600737512111664,\n",
              "  0.17304550111293793,\n",
              "  0.17093892395496368,\n",
              "  0.16913607716560364,\n",
              "  0.16747793555259705,\n",
              "  0.16595396399497986,\n",
              "  0.16471347212791443,\n",
              "  0.16372086107730865,\n",
              "  0.16282615065574646,\n",
              "  0.16201841831207275,\n",
              "  0.16126684844493866,\n",
              "  0.1603393256664276,\n",
              "  0.1595413237810135,\n",
              "  0.1587381362915039,\n",
              "  0.15800660848617554,\n",
              "  0.15722134709358215,\n",
              "  0.15632472932338715,\n",
              "  0.15552979707717896,\n",
              "  0.1549609899520874,\n",
              "  0.15451423823833466,\n",
              "  0.15405569970607758,\n",
              "  0.15366920828819275,\n",
              "  0.15331418812274933,\n",
              "  0.15293245017528534,\n",
              "  0.15256886184215546,\n",
              "  0.15224899351596832,\n",
              "  0.1518854945898056,\n",
              "  0.15153782069683075,\n",
              "  0.1511169970035553,\n",
              "  0.1507669985294342,\n",
              "  0.15032608807086945,\n",
              "  0.1499151885509491,\n",
              "  0.1496017575263977,\n",
              "  0.14922580122947693,\n",
              "  0.1487751007080078,\n",
              "  0.14817920327186584,\n",
              "  0.14741118252277374,\n",
              "  0.14656828343868256,\n",
              "  0.1454424262046814,\n",
              "  0.14425137639045715,\n",
              "  0.14265091717243195,\n",
              "  0.14155665040016174,\n",
              "  0.13997317850589752,\n",
              "  0.13662444055080414,\n",
              "  0.1335536688566208,\n",
              "  0.1305105984210968,\n",
              "  0.12505730986595154,\n",
              "  0.1212168037891388,\n",
              "  0.11835526674985886,\n",
              "  0.1168326735496521,\n",
              "  0.11773104220628738,\n",
              "  0.11439788341522217,\n",
              "  0.11452367156744003,\n",
              "  0.11699807643890381,\n",
              "  0.11132630705833435,\n",
              "  0.11186783760786057,\n",
              "  0.11033769696950912,\n",
              "  0.10900337994098663,\n",
              "  0.10862653702497482,\n",
              "  0.10681028664112091,\n",
              "  0.10595270991325378,\n",
              "  0.11113839596509933,\n",
              "  0.10651989281177521,\n",
              "  0.10436825454235077,\n",
              "  0.10735227912664413,\n",
              "  0.10417462140321732,\n",
              "  0.10256871581077576,\n",
              "  0.10326167941093445,\n",
              "  0.10073614865541458,\n",
              "  0.09981038421392441,\n",
              "  0.09960272908210754,\n",
              "  0.09729346632957458,\n",
              "  0.0957447737455368,\n",
              "  0.09526932239532471,\n",
              "  0.09357411414384842,\n",
              "  0.0938505083322525,\n",
              "  0.09172290563583374,\n",
              "  0.09492573887109756,\n",
              "  0.09797105938196182,\n",
              "  0.10822705924510956,\n",
              "  0.09133905172348022,\n",
              "  0.08912931382656097,\n",
              "  0.0887880027294159,\n",
              "  0.08474772423505783,\n",
              "  0.08300258219242096,\n",
              "  0.07906314730644226,\n",
              "  0.08166617155075073,\n",
              "  0.07939504086971283,\n",
              "  0.07869427651166916,\n",
              "  0.07607971876859665,\n",
              "  0.07311534881591797,\n",
              "  0.07000222057104111,\n",
              "  0.06790976226329803,\n",
              "  0.06647419184446335,\n",
              "  0.06605520099401474,\n",
              "  0.06723155826330185,\n",
              "  0.07143545895814896,\n",
              "  0.06875123828649521,\n",
              "  0.06980183720588684,\n",
              "  0.06459717452526093,\n",
              "  0.07359404861927032,\n",
              "  0.07020968943834305,\n",
              "  0.06674347072839737,\n",
              "  0.06235986575484276,\n",
              "  0.06298757344484329,\n",
              "  0.06091569736599922,\n",
              "  0.06650196015834808,\n",
              "  0.06135788932442665,\n",
              "  0.057038020342588425,\n",
              "  0.05914110690355301,\n",
              "  0.058983031660318375,\n",
              "  0.05420994758605957,\n",
              "  0.05351100116968155,\n",
              "  0.05440076068043709,\n",
              "  0.056050948798656464,\n",
              "  0.051650699228048325,\n",
              "  0.05108541622757912,\n",
              "  0.050537772476673126,\n",
              "  0.0545877106487751,\n",
              "  0.05512097477912903,\n",
              "  0.051672112196683884,\n",
              "  0.04891941323876381,\n",
              "  0.04874078929424286,\n",
              "  0.04695742204785347,\n",
              "  0.044790346175432205,\n",
              "  0.04869529977440834,\n",
              "  0.04498378187417984,\n",
              "  0.04222644120454788,\n",
              "  0.043341461569070816,\n",
              "  0.042629122734069824,\n",
              "  0.04154672101140022,\n",
              "  0.03933381289243698,\n",
              "  0.04118867591023445,\n",
              "  0.04167191684246063,\n",
              "  0.03636655583977699,\n",
              "  0.03719981014728546,\n",
              "  0.035398487001657486,\n",
              "  0.03416050598025322,\n",
              "  0.04335317388176918,\n",
              "  0.039579570293426514,\n",
              "  0.05555712804198265,\n",
              "  0.04002207890152931,\n",
              "  0.04248590022325516,\n",
              "  0.04367860406637192,\n",
              "  0.038580480962991714,\n",
              "  0.03824286162853241,\n",
              "  0.03891550004482269,\n",
              "  0.03804728016257286,\n",
              "  0.04299354553222656,\n",
              "  0.03573572263121605,\n",
              "  0.03186366707086563,\n",
              "  0.035480599850416183,\n",
              "  0.0327155664563179,\n",
              "  0.031207429245114326,\n",
              "  0.03656399995088577,\n",
              "  0.03192052245140076,\n",
              "  0.0301213376224041,\n",
              "  0.02904118411242962,\n",
              "  0.027791980654001236,\n",
              "  0.029441464692354202,\n",
              "  0.029226040467619896,\n",
              "  0.044905997812747955,\n",
              "  0.04082534462213516,\n",
              "  0.03733221814036369,\n",
              "  0.03566684201359749,\n",
              "  0.03133736178278923,\n",
              "  0.029920345172286034,\n",
              "  0.027442503720521927,\n",
              "  0.030454332008957863,\n",
              "  0.03911850228905678,\n",
              "  0.04081595689058304,\n",
              "  0.03845050185918808,\n",
              "  0.03335041552782059,\n",
              "  0.031242160126566887,\n",
              "  0.026254260912537575,\n",
              "  0.0258893221616745,\n",
              "  0.02481197565793991,\n",
              "  0.02934512309730053,\n",
              "  0.028413834050297737,\n",
              "  0.02591930888593197,\n",
              "  0.026359518989920616,\n",
              "  0.025008883327245712,\n",
              "  0.026893356814980507,\n",
              "  0.038865845650434494,\n",
              "  0.03264531493186951,\n",
              "  0.0333896242082119,\n",
              "  0.027094701305031776,\n",
              "  0.024681836366653442,\n",
              "  0.024711914360523224,\n",
              "  0.024697139859199524,\n",
              "  0.024364439770579338,\n",
              "  0.0233794953674078,\n",
              "  0.02178502455353737],\n",
              " 'mean_squared_logarithmic_error': [5.38803768157959,\n",
              "  1.248118281364441,\n",
              "  0.4627559781074524,\n",
              "  0.268706351518631,\n",
              "  0.21277044713497162,\n",
              "  0.19066660106182098,\n",
              "  0.18117688596248627,\n",
              "  0.17600737512111664,\n",
              "  0.17304550111293793,\n",
              "  0.17093892395496368,\n",
              "  0.16913607716560364,\n",
              "  0.16747793555259705,\n",
              "  0.16595396399497986,\n",
              "  0.16471347212791443,\n",
              "  0.16372086107730865,\n",
              "  0.16282615065574646,\n",
              "  0.16201841831207275,\n",
              "  0.16126684844493866,\n",
              "  0.1603393256664276,\n",
              "  0.1595413237810135,\n",
              "  0.1587381362915039,\n",
              "  0.15800660848617554,\n",
              "  0.15722134709358215,\n",
              "  0.15632472932338715,\n",
              "  0.15552979707717896,\n",
              "  0.1549609899520874,\n",
              "  0.15451423823833466,\n",
              "  0.15405569970607758,\n",
              "  0.15366920828819275,\n",
              "  0.15331418812274933,\n",
              "  0.15293245017528534,\n",
              "  0.15256886184215546,\n",
              "  0.15224899351596832,\n",
              "  0.1518854945898056,\n",
              "  0.15153782069683075,\n",
              "  0.1511169970035553,\n",
              "  0.1507669985294342,\n",
              "  0.15032608807086945,\n",
              "  0.1499151885509491,\n",
              "  0.1496017575263977,\n",
              "  0.14922580122947693,\n",
              "  0.1487751007080078,\n",
              "  0.14817920327186584,\n",
              "  0.14741118252277374,\n",
              "  0.14656828343868256,\n",
              "  0.1454424262046814,\n",
              "  0.14425137639045715,\n",
              "  0.14265091717243195,\n",
              "  0.14155665040016174,\n",
              "  0.13997317850589752,\n",
              "  0.13662444055080414,\n",
              "  0.1335536688566208,\n",
              "  0.1305105984210968,\n",
              "  0.12505730986595154,\n",
              "  0.1212168037891388,\n",
              "  0.11835526674985886,\n",
              "  0.1168326735496521,\n",
              "  0.11773104220628738,\n",
              "  0.11439788341522217,\n",
              "  0.11452367156744003,\n",
              "  0.11699807643890381,\n",
              "  0.11132630705833435,\n",
              "  0.11186783760786057,\n",
              "  0.11033769696950912,\n",
              "  0.10900337994098663,\n",
              "  0.10862653702497482,\n",
              "  0.10681028664112091,\n",
              "  0.10595270991325378,\n",
              "  0.11113839596509933,\n",
              "  0.10651989281177521,\n",
              "  0.10436825454235077,\n",
              "  0.10735227912664413,\n",
              "  0.10417462140321732,\n",
              "  0.10256871581077576,\n",
              "  0.10326167941093445,\n",
              "  0.10073614865541458,\n",
              "  0.09981038421392441,\n",
              "  0.09960272908210754,\n",
              "  0.09729346632957458,\n",
              "  0.0957447737455368,\n",
              "  0.09526932239532471,\n",
              "  0.09357411414384842,\n",
              "  0.0938505083322525,\n",
              "  0.09172290563583374,\n",
              "  0.09492573887109756,\n",
              "  0.09797105938196182,\n",
              "  0.10822705924510956,\n",
              "  0.09133905172348022,\n",
              "  0.08912931382656097,\n",
              "  0.0887880027294159,\n",
              "  0.08474772423505783,\n",
              "  0.08300258219242096,\n",
              "  0.07906314730644226,\n",
              "  0.08166617155075073,\n",
              "  0.07939504086971283,\n",
              "  0.07869427651166916,\n",
              "  0.07607971876859665,\n",
              "  0.07311534881591797,\n",
              "  0.07000222057104111,\n",
              "  0.06790976226329803,\n",
              "  0.06647419184446335,\n",
              "  0.06605520099401474,\n",
              "  0.06723155826330185,\n",
              "  0.07143545895814896,\n",
              "  0.06875123828649521,\n",
              "  0.06980183720588684,\n",
              "  0.06459717452526093,\n",
              "  0.07359404861927032,\n",
              "  0.07020968943834305,\n",
              "  0.06674347072839737,\n",
              "  0.06235986575484276,\n",
              "  0.06298757344484329,\n",
              "  0.06091569736599922,\n",
              "  0.06650196015834808,\n",
              "  0.06135788932442665,\n",
              "  0.057038020342588425,\n",
              "  0.05914110690355301,\n",
              "  0.058983031660318375,\n",
              "  0.05420994758605957,\n",
              "  0.05351100116968155,\n",
              "  0.05440076068043709,\n",
              "  0.056050948798656464,\n",
              "  0.051650699228048325,\n",
              "  0.05108541622757912,\n",
              "  0.050537772476673126,\n",
              "  0.0545877106487751,\n",
              "  0.05512097477912903,\n",
              "  0.051672112196683884,\n",
              "  0.04891941323876381,\n",
              "  0.04874078929424286,\n",
              "  0.04695742204785347,\n",
              "  0.044790346175432205,\n",
              "  0.04869529977440834,\n",
              "  0.04498378187417984,\n",
              "  0.04222644120454788,\n",
              "  0.043341461569070816,\n",
              "  0.042629122734069824,\n",
              "  0.04154672101140022,\n",
              "  0.03933381289243698,\n",
              "  0.04118867591023445,\n",
              "  0.04167191684246063,\n",
              "  0.03636655583977699,\n",
              "  0.03719981014728546,\n",
              "  0.035398487001657486,\n",
              "  0.03416050598025322,\n",
              "  0.04335317388176918,\n",
              "  0.039579570293426514,\n",
              "  0.05555712804198265,\n",
              "  0.04002207890152931,\n",
              "  0.04248590022325516,\n",
              "  0.04367860406637192,\n",
              "  0.038580480962991714,\n",
              "  0.03824286162853241,\n",
              "  0.03891550004482269,\n",
              "  0.03804728016257286,\n",
              "  0.04299354553222656,\n",
              "  0.03573572263121605,\n",
              "  0.03186366707086563,\n",
              "  0.035480599850416183,\n",
              "  0.0327155664563179,\n",
              "  0.031207429245114326,\n",
              "  0.03656399995088577,\n",
              "  0.03192052245140076,\n",
              "  0.0301213376224041,\n",
              "  0.02904118411242962,\n",
              "  0.027791980654001236,\n",
              "  0.029441464692354202,\n",
              "  0.029226040467619896,\n",
              "  0.044905997812747955,\n",
              "  0.04082534462213516,\n",
              "  0.03733221814036369,\n",
              "  0.03566684201359749,\n",
              "  0.03133736178278923,\n",
              "  0.029920345172286034,\n",
              "  0.027442503720521927,\n",
              "  0.030454332008957863,\n",
              "  0.03911850228905678,\n",
              "  0.04081595689058304,\n",
              "  0.03845050185918808,\n",
              "  0.03335041552782059,\n",
              "  0.031242160126566887,\n",
              "  0.026254260912537575,\n",
              "  0.0258893221616745,\n",
              "  0.02481197565793991,\n",
              "  0.02934512309730053,\n",
              "  0.028413834050297737,\n",
              "  0.02591930888593197,\n",
              "  0.026359518989920616,\n",
              "  0.025008883327245712,\n",
              "  0.026893356814980507,\n",
              "  0.038865845650434494,\n",
              "  0.03264531493186951,\n",
              "  0.0333896242082119,\n",
              "  0.027094701305031776,\n",
              "  0.024681836366653442,\n",
              "  0.024711914360523224,\n",
              "  0.024697139859199524,\n",
              "  0.024364439770579338,\n",
              "  0.0233794953674078,\n",
              "  0.02178502455353737],\n",
              " 'val_loss': [1.9758985042572021,\n",
              "  0.6698256134986877,\n",
              "  0.3468521237373352,\n",
              "  0.24674808979034424,\n",
              "  0.2093038260936737,\n",
              "  0.19290687143802643,\n",
              "  0.18451397120952606,\n",
              "  0.1793595254421234,\n",
              "  0.17567873001098633,\n",
              "  0.17274601757526398,\n",
              "  0.17032867670059204,\n",
              "  0.16787582635879517,\n",
              "  0.16566738486289978,\n",
              "  0.16391482949256897,\n",
              "  0.16233845055103302,\n",
              "  0.16097988188266754,\n",
              "  0.15973718464374542,\n",
              "  0.15829762816429138,\n",
              "  0.15680982172489166,\n",
              "  0.1555974781513214,\n",
              "  0.15423625707626343,\n",
              "  0.15283747017383575,\n",
              "  0.15124575793743134,\n",
              "  0.149652898311615,\n",
              "  0.14838647842407227,\n",
              "  0.147469162940979,\n",
              "  0.14671066403388977,\n",
              "  0.1458977609872818,\n",
              "  0.1451721042394638,\n",
              "  0.14460095763206482,\n",
              "  0.14386409521102905,\n",
              "  0.14337535202503204,\n",
              "  0.14280132949352264,\n",
              "  0.14207302033901215,\n",
              "  0.14135754108428955,\n",
              "  0.14082570374011993,\n",
              "  0.13991309702396393,\n",
              "  0.13921275734901428,\n",
              "  0.1387162059545517,\n",
              "  0.1383291482925415,\n",
              "  0.13797475397586823,\n",
              "  0.1374167650938034,\n",
              "  0.1364964097738266,\n",
              "  0.13580089807510376,\n",
              "  0.13499636948108673,\n",
              "  0.1347200870513916,\n",
              "  0.13393187522888184,\n",
              "  0.13242162764072418,\n",
              "  0.13062913715839386,\n",
              "  0.12960490584373474,\n",
              "  0.1290888637304306,\n",
              "  0.12907645106315613,\n",
              "  0.12798167765140533,\n",
              "  0.12287413328886032,\n",
              "  0.11989881098270416,\n",
              "  0.12084455788135529,\n",
              "  0.11665711551904678,\n",
              "  0.11280840635299683,\n",
              "  0.11439941823482513,\n",
              "  0.11215351521968842,\n",
              "  0.11253567785024643,\n",
              "  0.11976217478513718,\n",
              "  0.11062819510698318,\n",
              "  0.10800446569919586,\n",
              "  0.11040573567152023,\n",
              "  0.11040229350328445,\n",
              "  0.10300236195325851,\n",
              "  0.1101960763335228,\n",
              "  0.11013840138912201,\n",
              "  0.10222738981246948,\n",
              "  0.12067095190286636,\n",
              "  0.11098924279212952,\n",
              "  0.10586170107126236,\n",
              "  0.09909504652023315,\n",
              "  0.10038641095161438,\n",
              "  0.1031094640493393,\n",
              "  0.10766924172639847,\n",
              "  0.10107890516519547,\n",
              "  0.09771112352609634,\n",
              "  0.10656344890594482,\n",
              "  0.09699168056249619,\n",
              "  0.10148419439792633,\n",
              "  0.09490784257650375,\n",
              "  0.10327122360467911,\n",
              "  0.08610433340072632,\n",
              "  0.09268785268068314,\n",
              "  0.0952368751168251,\n",
              "  0.08526450395584106,\n",
              "  0.09141074120998383,\n",
              "  0.09250662475824356,\n",
              "  0.08427340537309647,\n",
              "  0.08410431444644928,\n",
              "  0.08336612582206726,\n",
              "  0.07844976335763931,\n",
              "  0.07713537663221359,\n",
              "  0.07672347128391266,\n",
              "  0.07727130502462387,\n",
              "  0.07411463558673859,\n",
              "  0.07217282801866531,\n",
              "  0.07096467167139053,\n",
              "  0.0690092220902443,\n",
              "  0.07034512609243393,\n",
              "  0.07271338999271393,\n",
              "  0.06789172440767288,\n",
              "  0.07199788838624954,\n",
              "  0.06836244463920593,\n",
              "  0.07227253913879395,\n",
              "  0.06538974493741989,\n",
              "  0.06906630843877792,\n",
              "  0.06822797656059265,\n",
              "  0.07214166969060898,\n",
              "  0.06336075812578201,\n",
              "  0.06947340816259384,\n",
              "  0.06778278201818466,\n",
              "  0.060102399438619614,\n",
              "  0.06408461183309555,\n",
              "  0.061204273253679276,\n",
              "  0.0585569404065609,\n",
              "  0.058838460594415665,\n",
              "  0.05893084034323692,\n",
              "  0.06119055673480034,\n",
              "  0.05740772560238838,\n",
              "  0.0565083809196949,\n",
              "  0.054088640958070755,\n",
              "  0.05597975105047226,\n",
              "  0.05498237535357475,\n",
              "  0.05500558391213417,\n",
              "  0.052553705871105194,\n",
              "  0.05148144066333771,\n",
              "  0.05023660883307457,\n",
              "  0.04893001914024353,\n",
              "  0.05576514080166817,\n",
              "  0.0493648536503315,\n",
              "  0.046559445559978485,\n",
              "  0.048557840287685394,\n",
              "  0.046975184231996536,\n",
              "  0.047225747257471085,\n",
              "  0.04423050582408905,\n",
              "  0.049933332949876785,\n",
              "  0.04706234484910965,\n",
              "  0.04237614944577217,\n",
              "  0.040899794548749924,\n",
              "  0.04068760946393013,\n",
              "  0.03980878368020058,\n",
              "  0.04159507155418396,\n",
              "  0.03863653168082237,\n",
              "  0.06822817772626877,\n",
              "  0.0401640422642231,\n",
              "  0.04310149326920509,\n",
              "  0.04994054511189461,\n",
              "  0.035944536328315735,\n",
              "  0.03788640350103378,\n",
              "  0.04926012083888054,\n",
              "  0.03482415899634361,\n",
              "  0.05000361055135727,\n",
              "  0.03896794468164444,\n",
              "  0.03325798362493515,\n",
              "  0.03677961230278015,\n",
              "  0.03462591767311096,\n",
              "  0.03336181864142418,\n",
              "  0.03926684334874153,\n",
              "  0.036660484969615936,\n",
              "  0.03270594775676727,\n",
              "  0.030533064156770706,\n",
              "  0.030398933216929436,\n",
              "  0.0325641967356205,\n",
              "  0.033055610954761505,\n",
              "  0.04907071590423584,\n",
              "  0.035432204604148865,\n",
              "  0.03379589319229126,\n",
              "  0.03856900706887245,\n",
              "  0.030538223683834076,\n",
              "  0.030156049877405167,\n",
              "  0.028644172474741936,\n",
              "  0.029269473627209663,\n",
              "  0.03350518271327019,\n",
              "  0.05145949497818947,\n",
              "  0.04170979559421539,\n",
              "  0.041489697992801666,\n",
              "  0.031070327386260033,\n",
              "  0.02887384034693241,\n",
              "  0.02790502831339836,\n",
              "  0.02518187277019024,\n",
              "  0.030606918036937714,\n",
              "  0.03230307251214981,\n",
              "  0.031691424548625946,\n",
              "  0.02810727246105671,\n",
              "  0.02835177257657051,\n",
              "  0.027844620868563652,\n",
              "  0.025470435619354248,\n",
              "  0.031227558851242065,\n",
              "  0.028628962114453316,\n",
              "  0.0271461121737957,\n",
              "  0.026726186275482178,\n",
              "  0.025075482204556465,\n",
              "  0.023633399978280067,\n",
              "  0.02392340637743473,\n",
              "  0.022731095552444458,\n",
              "  0.02234519273042679,\n",
              "  0.023755822330713272],\n",
              " 'val_mean_squared_logarithmic_error': [1.9758985042572021,\n",
              "  0.6698256134986877,\n",
              "  0.3468521237373352,\n",
              "  0.24674808979034424,\n",
              "  0.2093038260936737,\n",
              "  0.19290687143802643,\n",
              "  0.18451397120952606,\n",
              "  0.1793595254421234,\n",
              "  0.17567873001098633,\n",
              "  0.17274601757526398,\n",
              "  0.17032867670059204,\n",
              "  0.16787582635879517,\n",
              "  0.16566738486289978,\n",
              "  0.16391482949256897,\n",
              "  0.16233845055103302,\n",
              "  0.16097988188266754,\n",
              "  0.15973718464374542,\n",
              "  0.15829762816429138,\n",
              "  0.15680982172489166,\n",
              "  0.1555974781513214,\n",
              "  0.15423625707626343,\n",
              "  0.15283747017383575,\n",
              "  0.15124575793743134,\n",
              "  0.149652898311615,\n",
              "  0.14838647842407227,\n",
              "  0.147469162940979,\n",
              "  0.14671066403388977,\n",
              "  0.1458977609872818,\n",
              "  0.1451721042394638,\n",
              "  0.14460095763206482,\n",
              "  0.14386409521102905,\n",
              "  0.14337535202503204,\n",
              "  0.14280132949352264,\n",
              "  0.14207302033901215,\n",
              "  0.14135754108428955,\n",
              "  0.14082570374011993,\n",
              "  0.13991309702396393,\n",
              "  0.13921275734901428,\n",
              "  0.1387162059545517,\n",
              "  0.1383291482925415,\n",
              "  0.13797475397586823,\n",
              "  0.1374167650938034,\n",
              "  0.1364964097738266,\n",
              "  0.13580089807510376,\n",
              "  0.13499636948108673,\n",
              "  0.1347200870513916,\n",
              "  0.13393187522888184,\n",
              "  0.13242162764072418,\n",
              "  0.13062913715839386,\n",
              "  0.12960490584373474,\n",
              "  0.1290888637304306,\n",
              "  0.12907645106315613,\n",
              "  0.12798167765140533,\n",
              "  0.12287413328886032,\n",
              "  0.11989881098270416,\n",
              "  0.12084455788135529,\n",
              "  0.11665711551904678,\n",
              "  0.11280840635299683,\n",
              "  0.11439941823482513,\n",
              "  0.11215351521968842,\n",
              "  0.11253567785024643,\n",
              "  0.11976217478513718,\n",
              "  0.11062819510698318,\n",
              "  0.10800446569919586,\n",
              "  0.11040573567152023,\n",
              "  0.11040229350328445,\n",
              "  0.10300236195325851,\n",
              "  0.1101960763335228,\n",
              "  0.11013840138912201,\n",
              "  0.10222738981246948,\n",
              "  0.12067095190286636,\n",
              "  0.11098924279212952,\n",
              "  0.10586170107126236,\n",
              "  0.09909504652023315,\n",
              "  0.10038641095161438,\n",
              "  0.1031094640493393,\n",
              "  0.10766924172639847,\n",
              "  0.10107890516519547,\n",
              "  0.09771112352609634,\n",
              "  0.10656344890594482,\n",
              "  0.09699168056249619,\n",
              "  0.10148419439792633,\n",
              "  0.09490784257650375,\n",
              "  0.10327122360467911,\n",
              "  0.08610433340072632,\n",
              "  0.09268785268068314,\n",
              "  0.0952368751168251,\n",
              "  0.08526450395584106,\n",
              "  0.09141074120998383,\n",
              "  0.09250662475824356,\n",
              "  0.08427340537309647,\n",
              "  0.08410431444644928,\n",
              "  0.08336612582206726,\n",
              "  0.07844976335763931,\n",
              "  0.07713537663221359,\n",
              "  0.07672347128391266,\n",
              "  0.07727130502462387,\n",
              "  0.07411463558673859,\n",
              "  0.07217282801866531,\n",
              "  0.07096467167139053,\n",
              "  0.0690092220902443,\n",
              "  0.07034512609243393,\n",
              "  0.07271338999271393,\n",
              "  0.06789172440767288,\n",
              "  0.07199788838624954,\n",
              "  0.06836244463920593,\n",
              "  0.07227253913879395,\n",
              "  0.06538974493741989,\n",
              "  0.06906630843877792,\n",
              "  0.06822797656059265,\n",
              "  0.07214166969060898,\n",
              "  0.06336075812578201,\n",
              "  0.06947340816259384,\n",
              "  0.06778278201818466,\n",
              "  0.060102399438619614,\n",
              "  0.06408461183309555,\n",
              "  0.061204273253679276,\n",
              "  0.0585569404065609,\n",
              "  0.058838460594415665,\n",
              "  0.05893084034323692,\n",
              "  0.06119055673480034,\n",
              "  0.05740772560238838,\n",
              "  0.0565083809196949,\n",
              "  0.054088640958070755,\n",
              "  0.05597975105047226,\n",
              "  0.05498237535357475,\n",
              "  0.05500558391213417,\n",
              "  0.052553705871105194,\n",
              "  0.05148144066333771,\n",
              "  0.05023660883307457,\n",
              "  0.04893001914024353,\n",
              "  0.05576514080166817,\n",
              "  0.0493648536503315,\n",
              "  0.046559445559978485,\n",
              "  0.048557840287685394,\n",
              "  0.046975184231996536,\n",
              "  0.047225747257471085,\n",
              "  0.04423050582408905,\n",
              "  0.049933332949876785,\n",
              "  0.04706234484910965,\n",
              "  0.04237614944577217,\n",
              "  0.040899794548749924,\n",
              "  0.04068760946393013,\n",
              "  0.03980878368020058,\n",
              "  0.04159507155418396,\n",
              "  0.03863653168082237,\n",
              "  0.06822817772626877,\n",
              "  0.0401640422642231,\n",
              "  0.04310149326920509,\n",
              "  0.04994054511189461,\n",
              "  0.035944536328315735,\n",
              "  0.03788640350103378,\n",
              "  0.04926012083888054,\n",
              "  0.03482415899634361,\n",
              "  0.05000361055135727,\n",
              "  0.03896794468164444,\n",
              "  0.03325798362493515,\n",
              "  0.03677961230278015,\n",
              "  0.03462591767311096,\n",
              "  0.03336181864142418,\n",
              "  0.03926684334874153,\n",
              "  0.036660484969615936,\n",
              "  0.03270594775676727,\n",
              "  0.030533064156770706,\n",
              "  0.030398933216929436,\n",
              "  0.0325641967356205,\n",
              "  0.033055610954761505,\n",
              "  0.04907071590423584,\n",
              "  0.035432204604148865,\n",
              "  0.03379589319229126,\n",
              "  0.03856900706887245,\n",
              "  0.030538223683834076,\n",
              "  0.030156049877405167,\n",
              "  0.028644172474741936,\n",
              "  0.029269473627209663,\n",
              "  0.03350518271327019,\n",
              "  0.05145949497818947,\n",
              "  0.04170979559421539,\n",
              "  0.041489697992801666,\n",
              "  0.031070327386260033,\n",
              "  0.02887384034693241,\n",
              "  0.02790502831339836,\n",
              "  0.02518187277019024,\n",
              "  0.030606918036937714,\n",
              "  0.03230307251214981,\n",
              "  0.031691424548625946,\n",
              "  0.02810727246105671,\n",
              "  0.02835177257657051,\n",
              "  0.027844620868563652,\n",
              "  0.025470435619354248,\n",
              "  0.031227558851242065,\n",
              "  0.028628962114453316,\n",
              "  0.0271461121737957,\n",
              "  0.026726186275482178,\n",
              "  0.025075482204556465,\n",
              "  0.023633399978280067,\n",
              "  0.02392340637743473,\n",
              "  0.022731095552444458,\n",
              "  0.02234519273042679,\n",
              "  0.023755822330713272]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "\n",
        "history = model.fit(x_train_df, y_train, epochs=200, batch_size=64, validation_split=0.2)\n",
        "end_time = datetime.now()\n",
        "\n",
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0270 - mean_squared_logarithmic_error: 0.0270\n",
            "Loss, Accuracy:  [0.026961155235767365, 0.026961155235767365]\n",
            "Training Duration: 0:00:16.211345\n"
          ]
        }
      ],
      "source": [
        "result = model.evaluate(x_test_df, y_test)\n",
        "print('Loss, Accuracy: ', result)\n",
        "print('Training Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Xmf_JRJa_N8C"
      ],
      "name": "Part1_MNIST_Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
